// chat.js - GÅ‚Ã³wna pÄ™tla konwersacji

import chalk from 'chalk';
import inquirer from 'inquirer';
import { marked } from 'marked';
import { markedTerminal } from 'marked-terminal';
import { CONFIG } from './config.js';
import { validateInput } from './validator.js';
import {
  createConversation,
  saveConversation,
  buildMessageWindow,
  startAutoSave,
  stopAutoSave,
} from './history.js';
import { streamOllama, streamDemo } from './ollama.js';
import { handlePowerShellCommands, formatResultsForFeedback, isFileModifyingCommand } from './executor.js';
import { isCommand, handleCommand } from './commands.js';
import { readInput, loadCommandHistory, saveCommandHistory } from './input.js';
import { StreamStats } from './stats.js';
import { ThinkParser } from './think-parser.js';
import { processAndDisplayDiffs } from './diff-display.js';
import { extractCodeBlocks } from './parser.js';
import { processMentions } from './mentions.js';
import { logger } from './logger.js';
import { quickScanProject, buildQuickContext } from './analyzer.js';
import { loadMemory, saveMemory, buildMemoryContext } from './memory.js';

// Konfiguracja marked dla terminala
marked.use(markedTerminal({
  code: chalk.cyan,
  blockquote: chalk.gray.italic,
  html: chalk.gray,
  heading: chalk.green.bold,
  firstHeading: chalk.magenta.bold,
  hr: chalk.reset,
  listitem: chalk.reset,
  list: chalk.reset,
  table: chalk.reset,
  paragraph: chalk.reset,
  strong: chalk.bold,
  em: chalk.italic,
  codespan: chalk.yellow,
  del: chalk.dim.gray.strikethrough,
  link: chalk.blue,
  href: chalk.blue.underline,
}));

// Maksymalna liczba automatycznych prÃ³b naprawy bÅ‚Ä™dÃ³w
const MAX_AUTO_RETRY = 3;

/**
 * Ustawia nasÅ‚uchiwanie na Ctrl+C do przerwania generowania.
 * UÅ¼ywa process SIGINT zamiast raw mode Å¼eby nie blokowaÄ‡ stdin.
 * @returns {{abortController: AbortController, cleanup: () => void}}
 */
function setupAbortListener() {
  const abortController = new AbortController();
  let cleaned = false;

  const onSigint = () => {
    if (!cleaned) {
      console.log(chalk.yellow('\n\nâ¹ Przerwano generowanie (Ctrl+C)...'));
      abortController.abort();
    }
  };

  // NasÅ‚uchuj SIGINT (Ctrl+C) - nie wymaga raw mode
  process.on('SIGINT', onSigint);

  const cleanup = () => {
    if (!cleaned) {
      cleaned = true;
      process.removeListener('SIGINT', onSigint);
    }
  };

  return { abortController, cleanup };
}

/**
 * WysyÅ‚a wiadomoÅ›ci do modelu i zwraca odpowiedÅº.
 * @param {Object} state - Stan konwersacji
 * @param {Array} apiMessages - WiadomoÅ›ci dla API
 * @returns {Promise<{response: string, error: Error|null}>}
 */
async function getAIResponse(state, apiMessages) {
  console.log(chalk.blue('\nâ”Œâ”€ OdpowiedÅº AI ') + chalk.blue('â”€'.repeat(60)));
  console.log(chalk.gray('  (Ctrl+C aby przerwaÄ‡)'));
  process.stdout.write('\n');

  let fullResponse = '';
  let responseStats = null;
  const stats = new StreamStats();

  // Setup abort listener
  const { abortController, cleanup } = setupAbortListener();
  const abortSignal = abortController.signal;

  // ThinkParser â€” rozdziela <think>...</think> od odpowiedzi
  let thinkingStarted = false;
  const thinkParser = new ThinkParser({
    onThinkToken: (token) => {
      if (abortSignal.aborted) return;
      if (!thinkingStarted) {
        process.stdout.write(chalk.gray('\nðŸ’­ MyÅ›lenie:\n'));
        thinkingStarted = true;
      }
      process.stdout.write(chalk.gray.italic(token));
      stats.addThinkingTokens(1);
    },
    onResponseToken: (token) => {
      if (abortSignal.aborted) return;
      if (thinkingStarted) {
        process.stdout.write(chalk.gray('\n\n'));
        thinkingStarted = false;
      }
      process.stdout.write(token);
      stats.addResponseTokens(1);
    },
  });

  stats.start();

  try {
    if (CONFIG.DEMO_MODE) {
      await streamDemo(
        apiMessages[apiMessages.length - 1]?.content || '',
        (token) => thinkParser.push(token),
        (text, demoStats) => { fullResponse = text; responseStats = demoStats; },
        {
          messages: state.conversation.messages.map(m => ({ role: m.role, content: m.content })),
          hasProjectContext: !!state.projectContext,
          abortSignal,
        },
      );
    } else {
      await new Promise((resolve, reject) => {
        streamOllama(
          apiMessages,
          (token) => thinkParser.push(token),
          (text, ollamaStats) => { fullResponse = text; responseStats = ollamaStats; resolve(); },
          (err) => reject(err),
          abortSignal,
        );
      });
    }
  } catch (err) {
    cleanup();
    if (err.name === 'AbortError' || abortSignal.aborted) {
      console.log(chalk.blue('\nâ””' + 'â”€'.repeat(76)) + '\n');
      return { response: fullResponse || null, error: null, aborted: true, thinkParser };
    }
    console.log(chalk.red(`\n\nâœ– BÅ‚Ä…d komunikacji z AI: ${err.message}`));
    console.log(chalk.blue('\nâ””' + 'â”€'.repeat(76)) + '\n');
    return { response: null, error: err, thinkParser };
  }

  cleanup();

  thinkParser.flush();
  stats.stop();

  if (responseStats?.eval_count) {
    stats.setOllamaStats(responseStats);
  } else {
    stats.estimateFromText(thinkParser.responseText);
  }

  process.stdout.write('\n');
  const statsLine = thinkParser.thinkingText
    ? stats.formatWithThinking()
    : stats.format();
  console.log(chalk.gray('\n' + statsLine));
  console.log(chalk.blue('\nâ””' + 'â”€'.repeat(76)) + '\n');

  const cleanResponse = thinkParser.responseText || fullResponse;
  return { response: cleanResponse, error: null, thinkParser };
}

/**
 * Przetwarza turÄ™ AI: wysyÅ‚a zapytanie, wykonuje komendy, obsÅ‚uguje bÅ‚Ä™dy.
 * @param {Object} state - Stan konwersacji
 * @returns {Promise<boolean>} - true jeÅ›li sukces, false jeÅ›li bÅ‚Ä…d komunikacji
 */
async function processAITurn(state) {
  const { conversation } = state;

  logger.info('CHAT', 'Rozpoczynam turÄ™ AI');
  logger.debug('CHAT', `WiadomoÅ›ci w konwersacji: ${conversation.messages.length}`);
  logger.state('CHAT', { autoExecute: state.autoExecute, hasProjectContext: !!state.projectContext });

  for (let attempt = 0; attempt <= MAX_AUTO_RETRY; attempt++) {
    logger.debug('CHAT', `PrÃ³ba ${attempt + 1}/${MAX_AUTO_RETRY + 1}`);

    // Buduj system prompt (opcjonalnie z kontekstem projektu)
    let systemPrompt = CONFIG.SYSTEM_PROMPT;

    // Dodaj szybki kontekst struktury (zawsze jeÅ›li dostÄ™pny)
    if (state.quickContext) {
      systemPrompt += state.quickContext;
      logger.trace('CHAT', 'Dodano szybki kontekst struktury do prompta');
    }

    // Dodaj peÅ‚ny kontekst projektu (jeÅ›li uÅ¼yto /analyze)
    if (state.projectContext) {
      systemPrompt += state.projectContext;
      logger.trace('CHAT', 'Dodano peÅ‚ny kontekst projektu do prompta');
    }

    // Dodaj kontekst pamiÄ™ci
    if (state.memoryContext) {
      systemPrompt += state.memoryContext;
      logger.trace('CHAT', 'Dodano kontekst pamiÄ™ci do prompta');
    }

    // Buduj okno wiadomoÅ›ci dla API
    const apiMessages = buildMessageWindow(
      conversation.messages.map(m => ({ role: m.role, content: m.content })),
      systemPrompt,
    );

    logger.debug('CHAT', `WysyÅ‚am ${apiMessages.length} wiadomoÅ›ci do API`);
    logger.trace('CHAT', 'Ostatnia wiadomoÅ›Ä‡:', apiMessages[apiMessages.length - 1]?.content?.slice(0, 100));

    // Pobierz odpowiedÅº AI
    const { response, error, aborted } = await getAIResponse(state, apiMessages);

    if (error) {
      logger.error('CHAT', `BÅ‚Ä…d komunikacji: ${error.message}`);
      // UsuÅ„ ostatniÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika z historii przy bÅ‚Ä™dzie komunikacji
      if (conversation.messages.length > 0 &&
          conversation.messages[conversation.messages.length - 1].role === 'user') {
        conversation.messages.pop();
        logger.debug('CHAT', 'UsuniÄ™to ostatniÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika');
      }
      return false;
    }

    // JeÅ›li przerwano - zapisz czÄ™Å›ciowÄ… odpowiedÅº i zakoÅ„cz
    if (aborted) {
      logger.info('CHAT', 'Generowanie przerwane przez uÅ¼ytkownika');
      if (response) {
        conversation.messages.push({
          role: 'assistant',
          content: response + '\n\n[przerwano przez uÅ¼ytkownika]',
          timestamp: new Date().toISOString(),
        });
        logger.debug('CHAT', `Zapisano czÄ™Å›ciowÄ… odpowiedÅº (${response.length} znakÃ³w)`);
      }
      return true;
    }

    if (!response) continue;

    // Dodaj odpowiedÅº do historii
    conversation.messages.push({
      role: 'assistant',
      content: response,
      timestamp: new Date().toISOString(),
    });

    // WyÅ›wietl diffy jeÅ›li sÄ… w odpowiedzi
    const codeBlocks = extractCodeBlocks(response);
    const diffCount = processAndDisplayDiffs(response, codeBlocks);
    if (diffCount > 0) {
      console.log(chalk.gray(`ðŸ“Š WyÅ›wietlono ${diffCount} zmian w plikach\n`));
    }

    // ObsÅ‚uÅ¼ komendy PowerShell
    const cmdResults = await handlePowerShellCommands(response, state.autoExecute);
    const feedback = formatResultsForFeedback(cmdResults);

    // OdÅ›wieÅ¼ kontekst projektu po komendach modyfikujÄ…cych pliki
    const fileModified = cmdResults.some(r => !r.skipped && r.success && isFileModifyingCommand(r.command));
    if (fileModified) {
      try {
        const cwd = process.cwd();
        const freshScan = await quickScanProject(cwd, 3);
        state.quickContext = buildQuickContext(freshScan);
        logger.info('CHAT', 'OdÅ›wieÅ¼ono kontekst projektu po modyfikacji plikÃ³w');
      } catch (err) {
        logger.warn('CHAT', `Nie udaÅ‚o siÄ™ odÅ›wieÅ¼yÄ‡ kontekstu: ${err.message}`);
      }
    }

    // SprawdÅº czy byÅ‚y bÅ‚Ä™dy
    const hasErrors = cmdResults.some(r => !r.skipped && !r.success);

    if (!hasErrors) {
      // Sukces! MoÅ¼emy zakoÅ„czyÄ‡
      return true;
    }

    // ByÅ‚y bÅ‚Ä™dy - sprawdÅº czy moÅ¼emy ponowiÄ‡
    if (attempt < MAX_AUTO_RETRY) {
      logger.warn('CHAT', `BÅ‚Ä™dy w komendach - prÃ³ba naprawy ${attempt + 1}/${MAX_AUTO_RETRY}`);
      console.log(chalk.yellow(`\nðŸ”„ Wykryto bÅ‚Ä™dy w komendach - prÃ³ba naprawy (${attempt + 1}/${MAX_AUTO_RETRY})...\n`));

      // Dodaj feedback jako wiadomoÅ›Ä‡ uÅ¼ytkownika
      conversation.messages.push({
        role: 'user',
        content: feedback,
        timestamp: new Date().toISOString(),
      });

      logger.trace('CHAT', 'Feedback dla modelu:', feedback?.slice(0, 200));

      // Kontynuuj pÄ™tlÄ™ - model sprÃ³buje naprawiÄ‡
    } else {
      logger.error('CHAT', `OsiÄ…gniÄ™to limit prÃ³b (${MAX_AUTO_RETRY})`);
      console.log(chalk.red(`âš  OsiÄ…gniÄ™to limit automatycznych prÃ³b (${MAX_AUTO_RETRY}). ProszÄ™ o manualnÄ… interwencjÄ™.\n`));
      return true; // ZwrÃ³Ä‡ true Å¼eby nie usuwaÄ‡ wiadomoÅ›ci
    }
  }

  logger.info('CHAT', 'Tura AI zakoÅ„czona pomyÅ›lnie');
  return true;
}

/**
 * GÅ‚Ã³wna pÄ™tla konwersacji.
 */
export async function startChat() {
  // Inicjalizuj logger z env vars
  logger.init();

  logger.info('CHAT', 'Uruchamiam AI Coding CLI');
  logger.debug('CHAT', `Tryb: ${CONFIG.DEMO_MODE ? 'DEMO' : 'PRODUKCJA'}`);

  // ZaÅ‚aduj historiÄ™ komend
  await loadCommandHistory();
  logger.debug('CHAT', 'ZaÅ‚adowano historiÄ™ komend');

  // Inicjalizacja konwersacji
  const conversation = createConversation();
  logger.info('CHAT', `Nowa konwersacja: ${conversation.id}`);

  // ZaÅ‚aduj pamiÄ™Ä‡ z poprzednich sesji
  await loadMemory();
  const memoryContext = buildMemoryContext(process.cwd());
  logger.debug('CHAT', `PamiÄ™Ä‡ zaÅ‚adowana (${memoryContext.length} znakÃ³w kontekstu)`);

  // Stan wspÃ³Å‚dzielony z komendami
  const state = {
    conversation,
    projectContext: null,
    quickContext: null,
    memoryContext: memoryContext || null,
    autoExecute: false,
  };

  // Auto-skanowanie struktury projektu
  try {
    logger.debug('CHAT', 'Auto-skanowanie struktury projektu...');
    const cwd = process.cwd();
    const quickScan = await quickScanProject(cwd, 3);
    state.quickContext = buildQuickContext(quickScan);
    logger.info('CHAT', `ZaÅ‚adowano strukturÄ™: ${quickScan.files.length} plikÃ³w, ${quickScan.dirs.length} katalogÃ³w`);
  } catch (err) {
    logger.warn('CHAT', `Nie udaÅ‚o siÄ™ zeskanowaÄ‡ projektu: ${err.message}`);
  }

  // Auto-save
  startAutoSave(() => state.conversation);
  logger.debug('CHAT', 'Uruchomiono auto-save');

  try {
    // Banner
    console.clear();
    console.log(chalk.magenta.bold('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—'));
    console.log(chalk.magenta.bold('â•‘          ðŸ¤– AI Coding Assistant - Local CLI v2.0                     â•‘'));
    console.log(chalk.magenta.bold('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'));
    console.log(chalk.gray(`\nModel: ${CONFIG.MODEL_NAME}`));
    console.log(chalk.gray(`Server: ${CONFIG.OLLAMA_HOST}:${CONFIG.OLLAMA_PORT}`));
    console.log(chalk.gray(`Rozmowa: ${conversation.id}`));

    // PokaÅ¼ status kontekstu projektu
    if (state.quickContext) {
      console.log(chalk.green(`ðŸ“ Projekt: struktura zaÅ‚adowana automatycznie`));
      console.log(chalk.gray(`   Lokalizacja: ${process.cwd()}`));
    }

    console.log(chalk.gray('\nKomendy:'));
    console.log(chalk.gray('  /exit     - zapisz i wyjdÅº'));
    console.log(chalk.gray('  /clear    - wyczyÅ›Ä‡ historiÄ™'));
    console.log(chalk.gray('  /info     - konfiguracja'));
    console.log(chalk.gray('  /analyze  - peÅ‚na analiza projektu (z zawartoÅ›ciÄ… plikÃ³w)'));
    console.log(chalk.gray('  /autorun  - przeÅ‚Ä…cz auto-wykonywanie komend'));
    console.log(chalk.gray('  /debug    - wÅ‚Ä…cz/wyÅ‚Ä…cz logowanie'));
    console.log(chalk.gray('  /help     - peÅ‚na pomoc\n'));

    // GÅ‚Ã³wna pÄ™tla
    logger.debug('CHAT', 'WchodzÄ™ do gÅ‚Ã³wnej pÄ™tli');

    while (true) {
      const promptLabel = state.autoExecute
        ? chalk.green('Ty') + chalk.yellow(' [AUTO]') + chalk.green(':')
        : chalk.green('Ty:');
      const userInput = await readInput(promptLabel, 'ðŸ’¬');

      logger.trace('CHAT', `Input uÅ¼ytkownika: "${userInput.slice(0, 50)}..."`);

      // Komendy
      if (isCommand(userInput.trim())) {
        logger.debug('CHAT', `Komenda: ${userInput.trim().split(/\s+/)[0]}`);
        const result = await handleCommand(userInput.trim(), state);
        logger.debug('CHAT', `Wynik komendy: ${result.action}`);
        if (result.action === 'exit') {
          logger.info('CHAT', 'UÅ¼ytkownik koÅ„czy sesjÄ™');
          break;
        }
        continue;
      }

      // Walidacja
      const { valid, sanitized, warnings } = validateInput(userInput);

      if (!valid) {
        logger.warn('CHAT', 'Walidacja nie powiodÅ‚a siÄ™');
        continue;
      }

      for (const w of warnings) {
        console.log(chalk.yellow(`âš  ${w}`));
        logger.warn('CHAT', `OstrzeÅ¼enie walidacji: ${w}`);
      }

      // PrzetwÃ³rz @mentions (pliki/foldery)
      const { cleanedInput, context: mentionContext, mentions } = await processMentions(sanitized);

      if (mentions && mentions.length > 0) {
        logger.info('CHAT', `Znaleziono ${mentions.length} @mentions`);
        logger.debug('CHAT', 'Mentions:', mentions);
      }

      // Buduj treÅ›Ä‡ wiadomoÅ›ci z kontekstem plikÃ³w
      const messageContent = mentionContext
        ? `${cleanedInput}\n${mentionContext}`
        : cleanedInput;

      // Dodaj do historii
      conversation.messages.push({
        role: 'user',
        content: messageContent,
        timestamp: new Date().toISOString(),
      });

      // PrzetwÃ³rz turÄ™ AI (z automatycznym retry przy bÅ‚Ä™dach)
      await processAITurn(state);
    }
  } finally {
    stopAutoSave();
    await saveCommandHistory();
    await saveMemory();
    logger.debug('CHAT', 'PamiÄ™Ä‡ zapisana');
  }
}
