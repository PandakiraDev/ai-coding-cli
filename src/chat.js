// chat.js - GÅ‚Ã³wna pÄ™tla konwersacji

import chalk from 'chalk';
import inquirer from 'inquirer';
import { marked } from 'marked';
import { markedTerminal } from 'marked-terminal';
import { CONFIG } from './config.js';
import { validateInput } from './validator.js';
import {
  createConversation,
  saveConversation,
  buildMessageWindow,
  startAutoSave,
  stopAutoSave,
} from './history.js';
import { streamOllama, streamDemo } from './ollama.js';
import { handlePowerShellCommands, formatResultsForFeedback, isFileModifyingCommand, getWorkingDir } from './executor.js';
import { isCommand, handleCommand } from './commands.js';
import { readInput, loadCommandHistory, saveCommandHistory } from './input.js';
import { StreamStats } from './stats.js';
import { ThinkParser } from './think-parser.js';
import { processAndDisplayDiffs } from './diff-display.js';
import { extractCodeBlocks } from './parser.js';
import { processMentions } from './mentions.js';
import { logger } from './logger.js';
import { quickScanProject, buildQuickContext } from './analyzer.js';
import { loadMemory, saveMemory, buildMemoryContext } from './memory.js';

// Konfiguracja marked dla terminala
marked.use(markedTerminal({
  code: chalk.cyan,
  blockquote: chalk.gray.italic,
  html: chalk.gray,
  heading: chalk.green.bold,
  firstHeading: chalk.magenta.bold,
  hr: chalk.reset,
  listitem: chalk.reset,
  list: chalk.reset,
  table: chalk.reset,
  paragraph: chalk.reset,
  strong: chalk.bold,
  em: chalk.italic,
  codespan: chalk.yellow,
  del: chalk.dim.gray.strikethrough,
  link: chalk.blue,
  href: chalk.blue.underline,
}));

// Maksymalna liczba automatycznych prÃ³b naprawy bÅ‚Ä™dÃ³w
const MAX_AUTO_RETRY = 3;
// Maksymalna liczba automatycznych kontynuacji po sukcesie (krokÃ³w planu)
const MAX_AUTO_CONTINUE = 10;

/**
 * Ustawia nasÅ‚uchiwanie na Ctrl+C do przerwania generowania.
 * UÅ¼ywa process SIGINT zamiast raw mode Å¼eby nie blokowaÄ‡ stdin.
 * @returns {{abortController: AbortController, cleanup: () => void}}
 */
function setupAbortListener() {
  const abortController = new AbortController();
  let cleaned = false;

  const onSigint = () => {
    if (!cleaned) {
      console.log(chalk.yellow('\n\nâ¹ Przerwano generowanie (Ctrl+C)...'));
      abortController.abort();
    }
  };

  // NasÅ‚uchuj SIGINT (Ctrl+C) - nie wymaga raw mode
  process.on('SIGINT', onSigint);

  const cleanup = () => {
    if (!cleaned) {
      cleaned = true;
      process.removeListener('SIGINT', onSigint);
    }
  };

  return { abortController, cleanup };
}

/**
 * WysyÅ‚a wiadomoÅ›ci do modelu i zwraca odpowiedÅº.
 * @param {Object} state - Stan konwersacji
 * @param {Array} apiMessages - WiadomoÅ›ci dla API
 * @returns {Promise<{response: string, error: Error|null}>}
 */
async function getAIResponse(state, apiMessages) {
  console.log(chalk.blue('\nâ”Œâ”€ OdpowiedÅº AI ') + chalk.blue('â”€'.repeat(60)));
  console.log(chalk.gray('  (Ctrl+C aby przerwaÄ‡)'));
  process.stdout.write('\n');

  let fullResponse = '';
  let responseStats = null;
  const stats = new StreamStats();

  // Setup abort listener
  const { abortController, cleanup } = setupAbortListener();
  const abortSignal = abortController.signal;

  // ThinkParser â€” rozdziela <think>...</think> od odpowiedzi
  let thinkingStarted = false;
  const thinkParser = new ThinkParser({
    onThinkToken: (token) => {
      if (abortSignal.aborted) return;
      if (!thinkingStarted) {
        process.stdout.write(chalk.gray('\nðŸ’­ MyÅ›lenie:\n'));
        thinkingStarted = true;
      }
      process.stdout.write(chalk.gray.italic(token));
      stats.addThinkingTokens(1);
    },
    onResponseToken: (token) => {
      if (abortSignal.aborted) return;
      if (thinkingStarted) {
        process.stdout.write(chalk.gray('\n\n'));
        thinkingStarted = false;
      }
      process.stdout.write(token);
      stats.addResponseTokens(1);
    },
  });

  stats.start();

  try {
    if (CONFIG.DEMO_MODE) {
      await streamDemo(
        apiMessages[apiMessages.length - 1]?.content || '',
        (token) => thinkParser.push(token),
        (text, demoStats) => { fullResponse = text; responseStats = demoStats; },
        {
          messages: state.conversation.messages.map(m => ({ role: m.role, content: m.content })),
          hasProjectContext: !!state.projectContext,
          abortSignal,
        },
      );
    } else {
      await new Promise((resolve, reject) => {
        streamOllama(
          apiMessages,
          (token) => thinkParser.push(token),
          (text, ollamaStats) => { fullResponse = text; responseStats = ollamaStats; resolve(); },
          (err) => reject(err),
          abortSignal,
        );
      });
    }
  } catch (err) {
    cleanup();
    if (err.name === 'AbortError' || abortSignal.aborted) {
      console.log(chalk.blue('\nâ””' + 'â”€'.repeat(76)) + '\n');
      return { response: fullResponse || null, error: null, aborted: true, thinkParser };
    }
    console.log(chalk.red(`\n\nâœ– BÅ‚Ä…d komunikacji z AI: ${err.message}`));
    console.log(chalk.blue('\nâ””' + 'â”€'.repeat(76)) + '\n');
    return { response: null, error: err, thinkParser };
  }

  cleanup();

  thinkParser.flush();
  stats.stop();

  if (responseStats?.eval_count) {
    stats.setOllamaStats(responseStats);
  } else {
    stats.estimateFromText(thinkParser.responseText);
  }

  process.stdout.write('\n');
  const statsLine = thinkParser.thinkingText
    ? stats.formatWithThinking()
    : stats.format();
  console.log(chalk.gray('\n' + statsLine));
  console.log(chalk.blue('\nâ””' + 'â”€'.repeat(76)) + '\n');

  const cleanResponse = thinkParser.responseText || fullResponse;
  return { response: cleanResponse, error: null, thinkParser };
}

/**
 * Buduje system prompt z wszystkimi kontekstami.
 * @param {Object} state
 * @returns {string}
 */
function buildSystemPrompt(state) {
  let systemPrompt = CONFIG.SYSTEM_PROMPT;

  if (state.quickContext) {
    systemPrompt += state.quickContext;
  }
  if (state.projectContext) {
    systemPrompt += state.projectContext;
  }
  if (state.memoryContext) {
    systemPrompt += state.memoryContext;
  }

  return systemPrompt;
}

/**
 * OdÅ›wieÅ¼a kontekst projektu po komendach modyfikujÄ…cych pliki.
 * UÅ¼ywa katalogu roboczego z executora (Å›ledzi cd).
 * @param {Object} state
 * @param {Array} cmdResults
 */
async function refreshContextIfNeeded(state, cmdResults) {
  const fileModified = cmdResults.some(r => !r.skipped && r.success && isFileModifyingCommand(r.command));
  if (!fileModified) return;

  try {
    const cwd = getWorkingDir();
    const freshScan = await quickScanProject(cwd, 3);
    state.quickContext = buildQuickContext(freshScan);
    logger.info('CHAT', `OdÅ›wieÅ¼ono kontekst projektu (${cwd})`);
  } catch (err) {
    logger.warn('CHAT', `Nie udaÅ‚o siÄ™ odÅ›wieÅ¼yÄ‡ kontekstu: ${err.message}`);
  }
}

/**
 * WysyÅ‚a jednÄ… wiadomoÅ›Ä‡ do modelu i przetwarza odpowiedÅº.
 * Zwraca obiekt z wynikiem jednej iteracji.
 *
 * @param {Object} state
 * @returns {Promise<{done: boolean, ok: boolean, hasCommands: boolean, hasErrors: boolean, feedback: string|null}>}
 */
async function runOneAIIteration(state) {
  const { conversation } = state;

  const systemPrompt = buildSystemPrompt(state);
  const apiMessages = buildMessageWindow(
    conversation.messages.map(m => ({ role: m.role, content: m.content })),
    systemPrompt,
  );

  logger.debug('CHAT', `WysyÅ‚am ${apiMessages.length} wiadomoÅ›ci do API`);

  const { response, error, aborted } = await getAIResponse(state, apiMessages);

  if (error) {
    logger.error('CHAT', `BÅ‚Ä…d komunikacji: ${error.message}`);
    if (conversation.messages.length > 0 &&
        conversation.messages[conversation.messages.length - 1].role === 'user') {
      conversation.messages.pop();
    }
    return { done: true, ok: false, hasCommands: false, hasErrors: false, feedback: null };
  }

  if (aborted) {
    logger.info('CHAT', 'Generowanie przerwane przez uÅ¼ytkownika');
    if (response) {
      conversation.messages.push({
        role: 'assistant',
        content: response + '\n\n[przerwano przez uÅ¼ytkownika]',
        timestamp: new Date().toISOString(),
      });
    }
    return { done: true, ok: true, hasCommands: false, hasErrors: false, feedback: null };
  }

  if (!response) {
    return { done: false, ok: true, hasCommands: false, hasErrors: false, feedback: null };
  }

  // Dodaj odpowiedÅº do historii
  conversation.messages.push({
    role: 'assistant',
    content: response,
    timestamp: new Date().toISOString(),
  });

  // WyÅ›wietl diffy
  const codeBlocks = extractCodeBlocks(response);
  const diffCount = processAndDisplayDiffs(response, codeBlocks);
  if (diffCount > 0) {
    console.log(chalk.gray(`ðŸ“Š WyÅ›wietlono ${diffCount} zmian w plikach\n`));
  }

  // ObsÅ‚uÅ¼ komendy PowerShell
  const cmdResults = await handlePowerShellCommands(response, state.autoExecute);
  const feedback = formatResultsForFeedback(cmdResults);

  const executedCount = cmdResults.filter(r => !r.skipped).length;
  const hasErrors = cmdResults.some(r => !r.skipped && !r.success);

  // OdÅ›wieÅ¼ kontekst po modyfikacjach plikÃ³w
  await refreshContextIfNeeded(state, cmdResults);

  return {
    done: false,
    ok: true,
    hasCommands: executedCount > 0,
    hasErrors,
    feedback,
  };
}

/**
 * Przetwarza turÄ™ AI: wysyÅ‚a zapytanie, wykonuje komendy, obsÅ‚uguje bÅ‚Ä™dy.
 *
 * Dwie pÄ™tle:
 * - Kontynuacja (po sukcesie z komendami) â€” max MAX_AUTO_CONTINUE krokÃ³w
 * - Retry (po bÅ‚Ä™dzie) â€” max MAX_AUTO_RETRY prÃ³b naprawy
 *
 * @param {Object} state - Stan konwersacji
 * @returns {Promise<boolean>} - true jeÅ›li sukces, false jeÅ›li bÅ‚Ä…d komunikacji
 */
async function processAITurn(state) {
  const { conversation } = state;

  logger.info('CHAT', 'Rozpoczynam turÄ™ AI');
  logger.debug('CHAT', `WiadomoÅ›ci w konwersacji: ${conversation.messages.length}`);

  let retryCount = 0;
  let continueCount = 0;

  while (true) {
    logger.debug('CHAT', `Iteracja (kontynuacje: ${continueCount}, retry: ${retryCount})`);

    const result = await runOneAIIteration(state);

    // BÅ‚Ä…d komunikacji lub przerwanie â€” koniec
    if (result.done) {
      return result.ok;
    }

    // Brak odpowiedzi (np. pusty response) â€” powtÃ³rz
    if (!result.ok) continue;

    // Brak komend = odpowiedÅº konwersacyjna â€” koniec tury
    if (!result.hasCommands) {
      return true;
    }

    // Komendy bez bÅ‚Ä™dÃ³w â€” kontynuacja planu
    if (!result.hasErrors) {
      continueCount++;

      if (continueCount >= MAX_AUTO_CONTINUE) {
        logger.info('CHAT', `OsiÄ…gniÄ™to limit kontynuacji (${MAX_AUTO_CONTINUE})`);
        console.log(chalk.yellow(`\nâ¸ Wykonano ${MAX_AUTO_CONTINUE} krokÃ³w automatycznie. KontynuowaÄ‡?\n`));
        return true;
      }

      if (result.feedback) {
        // OdesÅ‚ij wyniki komend do modelu â€” niech kontynuuje plan
        conversation.messages.push({
          role: 'user',
          content: result.feedback,
          timestamp: new Date().toISOString(),
        });
        logger.info('CHAT', `Kontynuacja planu (krok ${continueCount}/${MAX_AUTO_CONTINUE})`);
        console.log(chalk.cyan(`\nâ–¶ Kontynuacja planu (krok ${continueCount})...\n`));
      } else {
        // Komendy wykonane ale brak feedbacku (np. pominiÄ™te) â€” koniec
        return true;
      }

      continue;
    }

    // Komendy z bÅ‚Ä™dem â€” retry
    retryCount++;

    if (retryCount > MAX_AUTO_RETRY) {
      logger.error('CHAT', `OsiÄ…gniÄ™to limit prÃ³b naprawy (${MAX_AUTO_RETRY})`);
      console.log(chalk.red(`\nâš  OsiÄ…gniÄ™to limit automatycznych prÃ³b naprawy (${MAX_AUTO_RETRY}). ProszÄ™ o manualnÄ… interwencjÄ™.\n`));
      return true;
    }

    logger.warn('CHAT', `BÅ‚Ä…d w komendzie â€” naprawa ${retryCount}/${MAX_AUTO_RETRY}`);
    console.log(chalk.yellow(`\nðŸ”„ BÅ‚Ä…d w komendzie â€” prÃ³ba naprawy (${retryCount}/${MAX_AUTO_RETRY})...\n`));

    // OdesÅ‚ij diagnostykÄ™ bÅ‚Ä™du do modelu
    conversation.messages.push({
      role: 'user',
      content: result.feedback,
      timestamp: new Date().toISOString(),
    });
  }
}

/**
 * GÅ‚Ã³wna pÄ™tla konwersacji.
 */
export async function startChat() {
  // Inicjalizuj logger z env vars
  logger.init();

  logger.info('CHAT', 'Uruchamiam AI Coding CLI');
  logger.debug('CHAT', `Tryb: ${CONFIG.DEMO_MODE ? 'DEMO' : 'PRODUKCJA'}`);

  // ZaÅ‚aduj historiÄ™ komend
  await loadCommandHistory();
  logger.debug('CHAT', 'ZaÅ‚adowano historiÄ™ komend');

  // Inicjalizacja konwersacji
  const conversation = createConversation();
  logger.info('CHAT', `Nowa konwersacja: ${conversation.id}`);

  // ZaÅ‚aduj pamiÄ™Ä‡ z poprzednich sesji
  await loadMemory();
  const memoryContext = buildMemoryContext(process.cwd());
  logger.debug('CHAT', `PamiÄ™Ä‡ zaÅ‚adowana (${memoryContext.length} znakÃ³w kontekstu)`);

  // Stan wspÃ³Å‚dzielony z komendami
  const state = {
    conversation,
    projectContext: null,
    quickContext: null,
    memoryContext: memoryContext || null,
    autoExecute: false,
  };

  // Auto-skanowanie struktury projektu
  try {
    logger.debug('CHAT', 'Auto-skanowanie struktury projektu...');
    const cwd = getWorkingDir();
    const quickScan = await quickScanProject(cwd, 3);
    state.quickContext = buildQuickContext(quickScan);
    logger.info('CHAT', `ZaÅ‚adowano strukturÄ™: ${quickScan.files.length} plikÃ³w, ${quickScan.dirs.length} katalogÃ³w`);
  } catch (err) {
    logger.warn('CHAT', `Nie udaÅ‚o siÄ™ zeskanowaÄ‡ projektu: ${err.message}`);
  }

  // Auto-save
  startAutoSave(() => state.conversation);
  logger.debug('CHAT', 'Uruchomiono auto-save');

  try {
    // Banner
    console.clear();
    console.log(chalk.magenta.bold('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—'));
    console.log(chalk.magenta.bold('â•‘          ðŸ¤– AI Coding Assistant - Local CLI v2.0                     â•‘'));
    console.log(chalk.magenta.bold('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'));
    console.log(chalk.gray(`\nModel: ${CONFIG.MODEL_NAME}`));
    console.log(chalk.gray(`Server: ${CONFIG.OLLAMA_HOST}:${CONFIG.OLLAMA_PORT}`));
    console.log(chalk.gray(`Rozmowa: ${conversation.id}`));

    // PokaÅ¼ status kontekstu projektu
    if (state.quickContext) {
      console.log(chalk.green(`ðŸ“ Projekt: struktura zaÅ‚adowana automatycznie`));
      console.log(chalk.gray(`   Lokalizacja: ${process.cwd()}`));
    }

    console.log(chalk.gray('\nKomendy:'));
    console.log(chalk.gray('  /exit     - zapisz i wyjdÅº'));
    console.log(chalk.gray('  /clear    - wyczyÅ›Ä‡ historiÄ™'));
    console.log(chalk.gray('  /info     - konfiguracja'));
    console.log(chalk.gray('  /analyze  - peÅ‚na analiza projektu (z zawartoÅ›ciÄ… plikÃ³w)'));
    console.log(chalk.gray('  /autorun  - przeÅ‚Ä…cz auto-wykonywanie komend'));
    console.log(chalk.gray('  /debug    - wÅ‚Ä…cz/wyÅ‚Ä…cz logowanie'));
    console.log(chalk.gray('  /help     - peÅ‚na pomoc\n'));

    // GÅ‚Ã³wna pÄ™tla
    logger.debug('CHAT', 'WchodzÄ™ do gÅ‚Ã³wnej pÄ™tli');

    while (true) {
      const promptLabel = state.autoExecute
        ? chalk.green('Ty') + chalk.yellow(' [AUTO]') + chalk.green(':')
        : chalk.green('Ty:');
      const userInput = await readInput(promptLabel, 'ðŸ’¬');

      logger.trace('CHAT', `Input uÅ¼ytkownika: "${userInput.slice(0, 50)}..."`);

      // Komendy
      if (isCommand(userInput.trim())) {
        logger.debug('CHAT', `Komenda: ${userInput.trim().split(/\s+/)[0]}`);
        const result = await handleCommand(userInput.trim(), state);
        logger.debug('CHAT', `Wynik komendy: ${result.action}`);
        if (result.action === 'exit') {
          logger.info('CHAT', 'UÅ¼ytkownik koÅ„czy sesjÄ™');
          break;
        }
        continue;
      }

      // Walidacja
      const { valid, sanitized, warnings } = validateInput(userInput);

      if (!valid) {
        logger.warn('CHAT', 'Walidacja nie powiodÅ‚a siÄ™');
        continue;
      }

      for (const w of warnings) {
        console.log(chalk.yellow(`âš  ${w}`));
        logger.warn('CHAT', `OstrzeÅ¼enie walidacji: ${w}`);
      }

      // PrzetwÃ³rz @mentions (pliki/foldery)
      const { cleanedInput, context: mentionContext, mentions } = await processMentions(sanitized);

      if (mentions && mentions.length > 0) {
        logger.info('CHAT', `Znaleziono ${mentions.length} @mentions`);
        logger.debug('CHAT', 'Mentions:', mentions);
      }

      // Buduj treÅ›Ä‡ wiadomoÅ›ci z kontekstem plikÃ³w
      const messageContent = mentionContext
        ? `${cleanedInput}\n${mentionContext}`
        : cleanedInput;

      // Dodaj do historii
      conversation.messages.push({
        role: 'user',
        content: messageContent,
        timestamp: new Date().toISOString(),
      });

      // PrzetwÃ³rz turÄ™ AI (z automatycznym retry przy bÅ‚Ä™dach)
      await processAITurn(state);
    }
  } finally {
    stopAutoSave();
    await saveCommandHistory();
    await saveMemory();
    logger.debug('CHAT', 'PamiÄ™Ä‡ zapisana');
  }
}
